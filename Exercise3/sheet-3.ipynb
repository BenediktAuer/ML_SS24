{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Deep Neural Networks and Learning Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you'll find various tasks encompassing both theoretical and coding exercises. Each exercise corresponds to a specific number of points, which are explicitly indicated within the task description.\n",
    "\n",
    "Always use the Jupyter kernel associated with the dedicated environment when compiling the notebook and completing your exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benedikt Auer, Paul Ludwig, Jannik Niebling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1 (Theory) (30/100)\n",
    "\n",
    "### Learning dynamics in the proximity of a local/global minimum\n",
    "\n",
    "**Task (1.a)** **(10 pts.)**\n",
    "Consider the learning dynamics close to the minimum $\\theta^*$ of an arbitrary cost function $\\mathcal{L}(\\theta)$ (of a single training parameter). Show that the dependence of the parameter $\\theta$ with respect to the step $t$ is \n",
    "$$\n",
    "\\theta^{(t)}\\approx\\theta^* + (1-\\eta\\mathcal{L}''(\\theta^*))^t(\\theta^{(0)}-\\theta^*)\n",
    "$$\n",
    "\n",
    "**Task (1.b)** **(20 pts.)**\n",
    "From the analytical solution you just derived (valid for arbitrary large, positive values of $\\eta$) read out:\n",
    "- (b.1) The range of $\\eta$ for which $\\theta^{(t)}$ converges asymptotically to $\\theta^*$ without overshooting. **(5 pts.)**\n",
    "- (b.2) The range of $\\eta$ for which $\\theta^{(t)}$ converges asymptotically to $\\theta^*$ even though it overshoots after every update step. **(5 pts.)**\n",
    "- (b.3) The range of $\\eta$ for which $\\theta^{(t)}$ does not converge asymptotically to $\\theta^*$. **(5 pts.)**\n",
    "- (b.4) The value of $\\eta$ for which one effectively applies the well known [Newton’s method](https://en.wikipedia.org/wiki/Newton%27s_method#Systems_of_equations). What happens in this case? **(5 pts.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (1.a)**\n",
    "Starting from the loss function $\\mathcal{L}(\\theta)$ it can be approximated in the region around the minimum at $\\theta^*$ using a Taylor expansion:\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\mathcal{L}(\\theta^*)+ \\mathcal{L}'(\\theta^*)(\\theta-\\theta^*)+ \\frac{1}{2}\\mathcal{L}''(\\theta^*)(\\theta-\\theta^*)^2+\\mathcal(O)((\\theta-\\theta^*)^3).\n",
    "$$\n",
    "Note that the first derivative vanishes since $\\theta^*$ is a minimum, thus yielding\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\mathcal{L}(\\theta^*)+ \\frac{1}{2}\\mathcal{L}''(\\theta^*)(\\theta-\\theta^*)^2+\\mathcal(O)((\\theta-\\theta^*)^3).\n",
    "$$\n",
    "\n",
    "The taylor expansion can be used to approximated the updating of the paramters during the backward pass,assuming that we are neare the minimum:\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)} = \\theta^{(t)}-\\eta\\nabla\\mathcal{L}(\\theta^{(t)}) \\approx \\theta^{(t)}-\\eta \\mathcal{L}''(\\theta^*)(\\theta^{(t)}-\\theta^*)\n",
    "$$\n",
    "Expanding the above quation with $\\theta^*-\\theta^*$ yields\n",
    "$$\n",
    "\\theta^{(t+1)}  \\approx \\theta^*-\\theta^*+ \\theta^{(t)}-\\eta \\mathcal{L}''(\\theta^*)(\\theta^{(t)}-\\theta^*) = \\theta^*+(\\theta^{(t)}-\\theta^*)-\\eta \\mathcal{L}''(\\theta^*)(\\theta^{(t)}-\\theta^*) = \\theta^*+(1-\\eta \\mathcal{L}''(\\theta^*))(\\theta^{(t)}-\\theta^*)\n",
    "$$\n",
    "Starting from an arbitrary  $\\theta^{(0)}$, $\\theta^{(1)}$ calcuates to:\n",
    "$$\n",
    "\\theta^{(1)} = \\theta^*+(1-\\eta \\mathcal{L}''(\\theta^*))(\\theta^{(0)}-\\theta^*)\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\theta^{(2)} = \\theta^*+(1-\\eta \\mathcal{L}''(\\theta^*))(\\theta^{(1)}-\\theta^*) =  \\theta^*+(1-\\eta \\mathcal{L}''(\\theta^*))\\big[ \\cancel{\\theta^*}+(1-\\eta \\mathcal{L}''(\\theta^*))(\\theta^{(0)}-\\theta^*)-\\cancel{\\theta^*}\\big] = \\theta^*+(1-\\eta \\mathcal{L}''(\\theta^*))^2(\\theta^{(0)}-\\theta^*).\n",
    "$$\n",
    "For any further step $t$ the previous for $\\theta^{(t-1)}$ introduced constant $\\theta^*$  gets canceld by the $\\theta^*$ inside of $(\\theta^{(t-1)}-\\theta^*)$, leaving an extra $(1-\\eta \\mathcal{L}''(\\theta^*))$ and $(\\theta^{(0)}-\\theta^*)$.\n",
    "\n",
    "Therefore, repeated application of the approximated update procidure leads to \n",
    "$$\n",
    "\\theta^{(t)}= \\theta^*+(1-\\eta \\mathcal{L}''(\\theta^*))^t(\\theta^{(0)}-\\theta^*).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (1.b)** <span style=\"color: red; font-size: 20pt;\">Nicht 100% sicher, nochmal drüberschauen</span>\n",
    "- (b.1) Since over shooting is forbidden, the expression  $(1-\\eta\\mathcal{L}''(\\theta^*))$ has to be larger than 0. To make sure it converges asymptotically to $\\theta^*$ it has to be $<|1|$, putting things together yields $$ 0 \\leq \\eta < \\frac{1}{\\mathcal{L}''(\\theta^*)}$$\n",
    "\n",
    "- (b.2) Over shooting is now allowed, therfore $(1-\\eta\\mathcal{L}''(\\theta^*)) < |1|$, resulting $$ 0< \\eta < \\frac{2}{\\mathcal{L}''(\\theta^*)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2 (Theory) (20/100)\n",
    "\n",
    "### Learning dynamics in the proximity of a local/global minimum (part 2)\n",
    "\n",
    "Generalize the solution in Problem **1.b.1** for a more realistic scenario in which the cost function $\\mathcal{L}(\\theta)$ is a function of a multidimensional parameter $\\theta$.        \n",
    "- For this excercise you have to compute the Hessian. Elaborate on what properties the Hessian should have in order for the problem to be well-defined.     \n",
    "- How does the intuition gained in Problem **1.b.1** transfer to this scenario?\n",
    "\n",
    ">Note: In this case the Hessian matrix reads\n",
    "> $$\n",
    "> H_{ij}=\\frac{\\partial^2 \\mathcal{L}}{\\partial\\theta_i\\partial\\theta_j}\n",
    "> $$\n",
    "\n",
    "\n",
    "> Hint: In this case, the Hessian matrix is multiplying the second-order term of the Taylor expansion, analogous to the curvature matrix $M$ multiplying the first-order term, as was introduced in the lecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here (Hier fehlt noch was)\n",
    "\n",
    "Properties of the Hessian matrix: Since we are considering a minimum the Hessian  has to be psotive definit at the minimum. This will also ensure that the curveature around the minimum is strictly positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 3 (Theory) (20/100)\n",
    "\n",
    "### Learning dynamics in the proximity of a local/global minimum (part 3)\n",
    "\n",
    "To get some intuition behind the Hessian matrix, let's consider an explicit example for a simple cost function of the form $\\mathcal{L}(\\theta)=\\theta_1\\theta_2$.\n",
    "\n",
    "- (3.a) Calculate the Hessian and show that the coordinates $\\theta=(0,0)$ correspond to a saddle point. **(10 pts.)**\n",
    "- (3.b) Consider the limit in which the learning rate is **very small** ($\\eta\\to 0$). Show that the trajectories $\\theta(t)$ during the gradient descent have the shape of an hyperbola $\\theta_1^2-\\theta_2^2=C$ with $C$ being a value dependent on the initial conditions. **(10 pts.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here\n",
    "a) The Hessian can be calculated, with the forumla given in exercise 2):\n",
    "$$\n",
    "\\frac{\\partial^2 \\mathcal{L}}{\\partial \\theta_1^2} = 0, \\quad \\frac{\\partial^2 \\mathcal{L}}{\\partial \\theta_2^2} = 0, \\quad \\frac{\\partial^2 \\mathcal{L}}{\\partial \\theta_1 \\partial \\theta_2} = 1, \\quad \\frac{\\partial^2 \\mathcal{L}}{\\partial \\theta_2 \\partial \\theta_1} = 1\n",
    "$$\n",
    "It follows that \n",
    "$$\n",
    "H(\\theta) = \\begin{bmatrix}\n",
    "\t0 & 1 \\\\\n",
    "\t1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Further more the gradient of $\\mathcal{L}$ is calulcated to:\n",
    "$$\n",
    "\\nabla_\\theta \\mathcal{L} = \\begin{bmatrix}\n",
    "\t\\theta_2 \\\\\n",
    "\t\\theta_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Obviously the gradient gets $0$ for $\\theta = (0,0)$ indicating a extrema or a saddle point.\n",
    "Do determine the type of extrema the Hessian matrix is diagonalized (we will skip the derivation and only state the result:)\n",
    "$$\n",
    "\\lambda_1 = 1,\\quad \\lambda_2 = -1\n",
    "$$\n",
    "The Hessian matrix is indefinit at $(0,0)$ and therefor $(0,0)$ is a saddle point.\n",
    "\n",
    "b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 4 (Theory) (30/100)\n",
    "\n",
    "### Incorporating noise into Gradient Descent\n",
    "\n",
    "In lecture 2, you have seen that when you optimize a given loss function $\\mathcal{L}(\\theta)$, function of model's parameters $\\theta$, you can identify a fixed point $\\theta^*$ such that $\\nabla_\\theta\\mathcal{L}(\\theta^*)=0$. In the proximity of this fixed point, you can taylor expand the gradient such that the following equation holds\n",
    "$$\n",
    "-\\nabla_\\theta \\mathcal{L}(\\theta) = 0 - \\lambda(\\theta - \\theta^*) + \\dots\n",
    "$$\n",
    "where $\\lambda$ is the curvature of the loss (being generalized to a matrix $M$ with the smallest eigenvalue $\\lambda$ in higher dimensions). It follows that there's an exponentially slow convergence around the fixed point $\\theta^*$, i.e., \n",
    "$$\n",
    "\\vert\\vert \\theta^{(t)} - \\theta^*\\vert\\vert \\propto e^{-\\lambda t}\n",
    "$$\n",
    "(see also excercises in sheet 4).\n",
    "\n",
    "- **Task 4.a (10 pts.)** In this exercise, you are asked to derive this important result. You can start by considering  $\\theta^*$ to be a fixed point for a one dimensional system with $\\theta \\in \\mathbb{R}^1$ where the dynamics are given by \n",
    "    $$\n",
    "    \\delta \\theta^{(t)}=-\\eta(\\lambda\\theta^{(t)})\n",
    "    $$\n",
    "    where $t$ represents a discrete time step, $\\lambda$ is the curvature of the loss function (e.g., eigenvalue of a 1-D hessian matrix). Morevoer, $\\delta \\theta^{(t)}$ corresponds to the difference between $\\theta^{(t+1)}$ and $\\theta^{(t)}$.\n",
    "\n",
    "- **Task 4.b (20 pts.)** In the last lecture you have also seen that Gradient Descent benefits when a stochastic component is added to it. Specifically, the fluctuations of the weights in the long-time limit, or *after convergence*, is given by \n",
    "    $$ \n",
    "    \\langle[\\theta(t)]^2\\rangle \\approx (\\frac{\\eta}{2N\\lambda}) \\textrm{Var}_x \\partial_\\theta \\mathcal{L}\n",
    "    $$. \n",
    "    In this second task, you are asked to derive this important result. You can start by considering  $\\theta^*$ to be a fixed point for a one dimensional system with $\\theta \\in \\mathbb{R}^1$ where the dynamics are given by \n",
    "    $$\n",
    "    \\delta \\theta^{(t)}=-\\eta(\\lambda\\theta^{(t)}+\\epsilon^{(t)})\n",
    "    $$\n",
    "    where $t$ represents a discrete time step, $\\lambda$ is the curvature of the loss function (e.g., eigenvalue of a 1-D hessian matrix) and $\\epsilon$ is some random noise. \n",
    "\n",
    "> Hint 1: you can start by considering the equation above in the form $\\theta^{(t+1)} = \\theta^{(t)} + \\delta \\theta^{(t)} = (1-\\eta\\lambda)\\theta^{(t)} - \\eta \\epsilon^{(t)}$\n",
    "\n",
    "> Hint 2: note that the sampling noise $\\epsilon$ is statistically independent in every time step $t$. Moreover since the noise is Gaussian $\\epsilon \\sim \\mathcal{N}(0, 1)$, it turns out that one can use the important Lemma for random variables which are statistically independent \n",
    "> $$ \\langle XY \\rangle = \\langle X \\rangle \\langle Y \\rangle $$\n",
    "> This results suggests that the noise at two different time steps $t_1, t_2$ is\n",
    "> $$ \\langle \\epsilon^{(t_1)}\\epsilon^{(t_2)}\\rangle = \\delta_{t_1, t_2}\\langle \\epsilon^2 \\rangle $$\n",
    "> where the $\\delta_{t_1,t_2}$ is the kronecker delta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Deep Neural Networks and Learning Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you'll find various tasks encompassing both theoretical and coding exercises. Each exercise corresponds to a specific number of points, which are explicitly indicated within the task description.\n",
    "\n",
    "Always use the Jupyter kernel associated with the dedicated environment when compiling the notebook and completing your exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1 (Theory) (30/100)\n",
    "\n",
    "### Learning dynamics in the proximity of a local/global minimum\n",
    "\n",
    "**Task (1.a)** **(10 pts.)**\n",
    "Consider the learning dynamics close to the minimum $\\theta^*$ of an arbitrary cost function $\\mathcal{L}(\\theta)$ (of a single training parameter). Show that the dependence of the parameter $\\theta$ with respect to the step $t$ is \n",
    "$$\n",
    "\\theta^{(t)}\\approx\\theta^* + (1-\\eta\\mathcal{L}''(\\theta^*))^t(\\theta^{(0)}-\\theta^*)\n",
    "$$\n",
    "\n",
    "**Task (1.b)** **(20 pts.)**\n",
    "From the analytical solution you just derived (valid for arbitrary large, positive values of $\\eta$) read out:\n",
    "- (b.1) The range of $\\eta$ for which $\\theta^{(t)}$ converges asymptotically to $\\theta^*$ without overshooting. **(5 pts.)**\n",
    "- (b.2) The range of $\\eta$ for which $\\theta^{(t)}$ converges asymptotically to $\\theta^*$ even though it overshoots after every update step. **(5 pts.)**\n",
    "- (b.3) The range of $\\eta$ for which $\\theta^{(t)}$ does not converge asymptotically to $\\theta^*$. **(5 pts.)**\n",
    "- (b.4) The value of $\\eta$ for which one effectively applies the well known [Newtonâ€™s method](https://en.wikipedia.org/wiki/Newton%27s_method#Systems_of_equations). What happens in this case? **(5 pts.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2 (Theory) (20/100)\n",
    "\n",
    "### Learning dynamics in the proximity of a local/global minimum (part 2)\n",
    "\n",
    "Generalize the solution in Problem **1.b.1** for a more realistic scenario in which the cost function $\\mathcal{L}(\\theta)$ is a function of a multidimensional parameter $\\theta$.        \n",
    "- For this excercise you have to compute the Hessian. Elaborate on what properties the Hessian should have in order for the problem to be well-defined.     \n",
    "- How does the intuition gained in Problem **1.b.1** transfer to this scenario?\n",
    "\n",
    ">Note: In this case the Hessian matrix reads\n",
    "> $$\n",
    "> H_{ij}=\\frac{\\partial^2 \\mathcal{L}}{\\partial\\theta_i\\partial\\theta_j}\n",
    "> $$\n",
    "\n",
    "\n",
    "> Hint: In this case, the Hessian matrix is multiplying the second-order term of the Taylor expansion, analogous to the curvature matrix $M$ multiplying the first-order term, as was introduced in the lecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 3 (Theory) (20/100)\n",
    "\n",
    "### Learning dynamics in the proximity of a local/global minimum (part 3)\n",
    "\n",
    "To get some intuition behind the Hessian matrix, let's consider an explicit example for a simple cost function of the form $\\mathcal{L}(\\theta)=\\theta_1\\theta_2$.\n",
    "\n",
    "- (3.a) Calculate the Hessian and show that the coordinates $\\theta=(0,0)$ correspond to a saddle point. **(10 pts.)**\n",
    "- (3.b) Consider the limit in which the learning rate is **very small** ($\\eta\\to 0$). Show that the trajectories $\\theta(t)$ during the gradient descent have the shape of an hyperbola $\\theta_1^2-\\theta_2^2=C$ with $C$ being a value dependent on the initial conditions. **(10 pts.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 4 (Theory) (30/100)\n",
    "\n",
    "### Incorporating noise into Gradient Descent\n",
    "\n",
    "In lecture 2, you have seen that when you optimize a given loss function $\\mathcal{L}(\\theta)$, function of model's parameters $\\theta$, you can identify a fixed point $\\theta^*$ such that $\\nabla_\\theta\\mathcal{L}(\\theta^*)=0$. In the proximity of this fixed point, you can taylor expand the gradient such that the following equation holds\n",
    "$$\n",
    "-\\nabla_\\theta \\mathcal{L}(\\theta) = 0 - \\lambda(\\theta - \\theta^*) + \\dots\n",
    "$$\n",
    "where $\\lambda$ is the curvature of the loss (being generalized to a matrix $M$ with the smallest eigenvalue $\\lambda$ in higher dimensions). It follows that there's an exponentially slow convergence around the fixed point $\\theta^*$, i.e., \n",
    "$$\n",
    "\\vert\\vert \\theta^{(t)} - \\theta^*\\vert\\vert \\propto e^{-\\lambda t}\n",
    "$$\n",
    "(see also excercises in sheet 4).\n",
    "\n",
    "- **Task 4.a (10 pts.)** In this exercise, you are asked to derive this important result. You can start by considering  $\\theta^*$ to be a fixed point for a one dimensional system with $\\theta \\in \\mathbb{R}^1$ where the dynamics are given by \n",
    "    $$\n",
    "    \\delta \\theta^{(t)}=-\\eta(\\lambda\\theta^{(t)})\n",
    "    $$\n",
    "    where $t$ represents a discrete time step, $\\lambda$ is the curvature of the loss function (e.g., eigenvalue of a 1-D hessian matrix). Morevoer, $\\delta \\theta^{(t)}$ corresponds to the difference between $\\theta^{(t+1)}$ and $\\theta^{(t)}$.\n",
    "\n",
    "- **Task 4.b (20 pts.)** In the last lecture you have also seen that Gradient Descent benefits when a stochastic component is added to it. Specifically, the fluctuations of the weights in the long-time limit, or *after convergence*, is given by \n",
    "    $$ \n",
    "    \\langle[\\theta(t)]^2\\rangle \\approx (\\frac{\\eta}{2N\\lambda}) \\textrm{Var}_x \\partial_\\theta \\mathcal{L}\n",
    "    $$. \n",
    "    In this second task, you are asked to derive this important result. You can start by considering  $\\theta^*$ to be a fixed point for a one dimensional system with $\\theta \\in \\mathbb{R}^1$ where the dynamics are given by \n",
    "    $$\n",
    "    \\delta \\theta^{(t)}=-\\eta(\\lambda\\theta^{(t)}+\\epsilon^{(t)})\n",
    "    $$\n",
    "    where $t$ represents a discrete time step, $\\lambda$ is the curvature of the loss function (e.g., eigenvalue of a 1-D hessian matrix) and $\\epsilon$ is some random noise. \n",
    "\n",
    "> Hint 1: you can start by considering the equation above in the form $\\theta^{(t+1)} = \\theta^{(t)} + \\delta \\theta^{(t)} = (1-\\eta\\lambda)\\theta^{(t)} - \\eta \\epsilon^{(t)}$\n",
    "\n",
    "> Hint 2: note that the sampling noise $\\epsilon$ is statistically independent in every time step $t$. Moreover since the noise is Gaussian $\\epsilon \\sim \\mathcal{N}(0, 1)$, it turns out that one can use the important Lemma for random variables which are statistically independent \n",
    "> $$ \\langle XY \\rangle = \\langle X \\rangle \\langle Y \\rangle $$\n",
    "> This results suggests that the noise at two different time steps $t_1, t_2$ is\n",
    "> $$ \\langle \\epsilon^{(t_1)}\\epsilon^{(t_2)}\\rangle = \\delta_{t_1, t_2}\\langle \\epsilon^2 \\rangle $$\n",
    "> where the $\\delta_{t_1,t_2}$ is the kronecker delta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Your solution here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
